{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHKHoIEkfmuPf1fq78yiej"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"awfRLEepFKw1","executionInfo":{"status":"ok","timestamp":1746711200824,"user_tz":-330,"elapsed":24,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"outputs":[],"source":["import numpy as np\n","\n","states = [0, 1, 2, 3]\n","actions = [\"a\", \"b\"]\n","\n","transition_prob = {\n","    0: {\"a\": [(1.0, 1, 0)], \"b\": [(1.0, 2, 0)]},\n","    1: {\"a\": [(1.0, 3, 1)], \"b\": [(1.0, 0, 0)]},\n","    2: {\"a\": [(1.0, 0, 0)], \"b\": [(1.0, 3, 1)]},\n","    3: {\"a\": [(1.0, 3, 0)], \"b\": [(1.0, 3, 0)]},\n","}"]},{"cell_type":"code","source":["disc_fact = 0.9\n","\n","def value_iteration(states, actions, transition_prob, disc_fact, theta=1e-6):\n","    v = np.zeros(len(states))\n","    while True:\n","        delta = 0\n","        for s in range(len(states)):\n","            old_v = v[s]\n","            max_value = float(\"-inf\")\n","            for a in actions:\n","                value = sum(\n","                    prob * (reward + disc_fact * v[next_state])\n","                    for prob, next_state, reward in transition_prob[s][a]\n","                )\n","                max_value = max(max_value, value)\n","            v[s] = max_value\n","            delta = max(delta, abs(old_v - v[s]))\n","        if delta < theta:\n","            break\n","    policy = {s: None for s in range(len(states))}\n","    for s in range(len(states)):\n","        action_values = {}\n","        for a in actions:\n","            action_values[a] = sum(\n","                prob * (reward + disc_fact * v[next_state])\n","                for prob, next_state, reward in transition_prob[s][a]\n","            )\n","        policy[s] = max(action_values, key=action_values.get)\n","    return v, policy"],"metadata":{"id":"-5VV7165GV1E","executionInfo":{"status":"ok","timestamp":1746711209944,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def policy_iteration(states, actions, transition_prob, disc_fact, theta=1e-6):\n","    policy = {s: np.random.choice(actions) for s in range(len(states))}\n","    v = np.zeros(len(states))\n","    while True:\n","        while True:\n","            delta = 0\n","            for s in range(len(states)):\n","                old_v = v[s]\n","                a = policy[s]\n","                v[s] = sum(\n","                    prob * (reward + disc_fact * v[next_state])\n","                    for prob, next_state, reward in transition_prob[s][a]\n","                )\n","                delta = max(delta, abs(old_v - v[s]))\n","            if delta < theta:\n","                break\n","        policy_stable = True\n","        for s in range(len(states)):\n","            old_action = policy[s]\n","            action_values = {}\n","            for a in actions:\n","                action_values[a] = sum(\n","                    prob * (reward + disc_fact * v[next_state])\n","                    for prob, next_state, reward in transition_prob[s][a]\n","                )\n","            new_action = max(action_values, key=action_values.get)\n","            policy[s] = new_action\n","            if old_action != new_action:\n","                policy_stable = False\n","        if policy_stable:\n","            break\n","    return v, policy"],"metadata":{"id":"9lbWSHgWGecf","executionInfo":{"status":"ok","timestamp":1746711211963,"user_tz":-330,"elapsed":17,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["V_vi, policy_vi = value_iteration(states, actions, transition_prob, disc_fact)\n","print(\"Value Iteration Results:\")\n","print(\"Optimal Values:\", V_vi)\n","print(\"Optimal Policy:\", policy_vi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAc5TNxqGe7y","executionInfo":{"status":"ok","timestamp":1746711220128,"user_tz":-330,"elapsed":19,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}},"outputId":"fec77d85-12c3-4996-d557-91504dda7cdd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Value Iteration Results:\n","Optimal Values: [0.9 1.  1.  0. ]\n","Optimal Policy: {0: 'a', 1: 'a', 2: 'b', 3: 'a'}\n"]}]},{"cell_type":"code","source":["V_pi, policy_pi = policy_iteration(states, actions, transition_prob, disc_fact)\n","print(\"Policy Iteration Results:\")\n","print(\"Optimal Values:\", V_pi)\n","print(\"Optimal Policy:\", policy_pi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G96_c8PjGg7s","executionInfo":{"status":"ok","timestamp":1746711228007,"user_tz":-330,"elapsed":42,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}},"outputId":"2c32e7c5-c060-490f-d7ac-d2156d141155"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Policy Iteration Results:\n","Optimal Values: [0.9 1.  1.  0. ]\n","Optimal Policy: {0: 'a', 1: 'a', 2: 'b', 3: 'a'}\n"]}]}]}