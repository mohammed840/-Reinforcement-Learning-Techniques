{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbdNCufh9LkLxO0kyTN/OL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5BLuyisoPqcW","executionInfo":{"status":"ok","timestamp":1746713663006,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"outputs":[],"source":["import numpy as np\n","\n","GRID_SIZE = 4\n","GOAL_STATE = (3, 3)\n","START_STATE = (0, 0)\n","ACTIONS = ['U', 'D', 'L', 'R']\n","\n","REWARD_GOAL = 1\n","REWARD_DEFAULT = 0\n","REWARD_INVALID = -1"]},{"cell_type":"code","source":["def get_next_state(state, action):\n","    x, y = state\n","    if action == 'U':\n","        return (max(x - 1, 0), y)\n","    if action == 'D':\n","        return (min(x + 1, GRID_SIZE - 1), y)\n","    if action == 'L':\n","        return (x, max(y - 1, 0))\n","    if action == 'R':\n","        return (x, min(y + 1, GRID_SIZE - 1))"],"metadata":{"id":"JSLr5THWP1Sf","executionInfo":{"status":"ok","timestamp":1746713677294,"user_tz":-330,"elapsed":9,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def get_reward(state):\n","    if state == GOAL_STATE:\n","        return REWARD_GOAL\n","    return REWARD_DEFAULT"],"metadata":{"id":"93IVD4FVP4y-","executionInfo":{"status":"ok","timestamp":1746713683103,"user_tz":-330,"elapsed":50,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def value_iteration(gamma=0.9, threshold=1e-6):\n","    V = np.zeros((GRID_SIZE, GRID_SIZE))\n","    delta = float('inf')\n","    while delta > threshold:\n","        delta = 0\n","        for x in range(GRID_SIZE):\n","            for y in range(GRID_SIZE):\n","                state = (x, y)\n","                if state == GOAL_STATE:\n","                    continue\n","                v = V[x, y]\n","                max_value = float('-inf')\n","                for action in ACTIONS:\n","                    next_state = get_next_state(state, action)\n","                    reward = get_reward(next_state)\n","                    value = reward + gamma * V[next_state]\n","                    max_value = max(max_value, value)\n","                V[x, y] = max_value\n","                delta = max(delta, abs(v - V[x, y]))\n","    return V"],"metadata":{"id":"KralrH8bP6NJ","executionInfo":{"status":"ok","timestamp":1746713691297,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def policy_iteration(gamma=0.9, threshold=1e-6):\n","    V = np.zeros((GRID_SIZE, GRID_SIZE))\n","    policy = {state: np.random.choice(ACTIONS) for state in [(x, y) for x in range(GRID_SIZE) for y in range(GRID_SIZE)]}\n","    policy_stable = False\n","    while not policy_stable:\n","        while True:\n","            delta = 0\n","            new_V = np.copy(V)\n","            for x in range(GRID_SIZE):\n","                for y in range(GRID_SIZE):\n","                    state = (x, y)\n","                    if state == GOAL_STATE:\n","                        continue\n","                    action = policy[state]\n","                    next_state = get_next_state(state, action)\n","                    reward = get_reward(next_state)\n","                    new_V[x, y] = reward + gamma * V[next_state]\n","                    delta = max(delta, np.abs(V[x, y] - new_V[x, y]))\n","            V = np.copy(new_V)\n","            if delta < threshold:\n","                break\n","        policy_stable = True\n","        for x in range(GRID_SIZE):\n","            for y in range(GRID_SIZE):\n","                state = (x, y)\n","                if state == GOAL_STATE:\n","                    continue\n","                old_action = policy[state]\n","                max_value = float('-inf')\n","                best_action = None\n","                for action in ACTIONS:\n","                    next_state = get_next_state(state, action)\n","                    reward = get_reward(next_state)\n","                    value = reward + gamma * V[next_state]\n","                    if value > max_value:\n","                        max_value = value\n","                        best_action = action\n","                policy[state] = best_action\n","                if old_action != best_action:\n","                    policy_stable = False\n","    return V, policy"],"metadata":{"id":"lPKdLEm7P8Nc","executionInfo":{"status":"ok","timestamp":1746713698420,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(\"Running Value Iteration...\")\n","V_value_iter = value_iteration()\n","print(\"Value Function after Value Iteration:\")\n","print(V_value_iter)\n","\n","print(\"\\nRunning Policy Iteration...\")\n","V_policy_iter, policy_iter = policy_iteration()\n","\n","print(\"\\nValue Function after Policy Iteration:\")\n","print(V_policy_iter)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XNAEWk3P981","executionInfo":{"status":"ok","timestamp":1746713707016,"user_tz":-330,"elapsed":34,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}},"outputId":"dfca262c-3136-4a69-9edd-4060df69f7eb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Value Iteration...\n","Value Function after Value Iteration:\n","[[0.59049 0.6561  0.729   0.81   ]\n"," [0.6561  0.729   0.81    0.9    ]\n"," [0.729   0.81    0.9     1.     ]\n"," [0.81    0.9     1.      0.     ]]\n","\n","Running Policy Iteration...\n","\n","Value Function after Policy Iteration:\n","[[0.59049 0.6561  0.729   0.81   ]\n"," [0.6561  0.729   0.81    0.9    ]\n"," [0.729   0.81    0.9     1.     ]\n"," [0.81    0.9     1.      0.     ]]\n"]}]},{"cell_type":"code","source":["print(\"\\nOptimal Policy after Policy Iteration:\")\n","for x in range(GRID_SIZE):\n","    for y in range(GRID_SIZE):\n","        state = (x, y)\n","        if state == GOAL_STATE:\n","            print(f\"({x}, {y}) -> Goal\")\n","        else:\n","            print(f\"({x}, {y}) -> {policy_iter[state]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHgK8Sf8QAC0","executionInfo":{"status":"ok","timestamp":1746713714656,"user_tz":-330,"elapsed":29,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}},"outputId":"452f80ce-af67-498c-ae67-908ffb79387b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Optimal Policy after Policy Iteration:\n","(0, 0) -> D\n","(0, 1) -> D\n","(0, 2) -> D\n","(0, 3) -> D\n","(1, 0) -> D\n","(1, 1) -> D\n","(1, 2) -> D\n","(1, 3) -> D\n","(2, 0) -> D\n","(2, 1) -> D\n","(2, 2) -> D\n","(2, 3) -> D\n","(3, 0) -> R\n","(3, 1) -> R\n","(3, 2) -> R\n","(3, 3) -> Goal\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rmBjsgckQB6P"},"execution_count":null,"outputs":[]}]}