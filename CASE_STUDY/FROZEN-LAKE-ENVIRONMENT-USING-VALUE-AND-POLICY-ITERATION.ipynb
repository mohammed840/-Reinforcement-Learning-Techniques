{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlyPp9banWfh3p/dhwxbKS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mvpWnGKWmxsz","executionInfo":{"status":"ok","timestamp":1748498093263,"user_tz":-330,"elapsed":450,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"outputs":[],"source":["import numpy as np\n","import gymnasium as gym\n","import time"]},{"cell_type":"code","source":["env = gym.make(\"FrozenLake-v1\", is_slippery=True, render_mode=\"human\")\n","env = env.unwrapped\n","\n","num_states = env.observation_space.n\n","num_actions = env.action_space.n\n","gamma = 0.9"],"metadata":{"id":"ze-2W0lNm3cC","executionInfo":{"status":"ok","timestamp":1748498093343,"user_tz":-330,"elapsed":42,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def value_iteration(env, gamma=0.9, theta=1e-6):\n","    V = np.zeros(num_states)\n","    policy = np.zeros(num_states, dtype=int)\n","    while True:\n","        delta = 0\n","        for state in range(num_states):\n","            action_values = np.zeros(num_actions)\n","            for action in range(num_actions):\n","                for prob, next_state, reward, done in env.P[state][action]:\n","                    action_values[action] += prob * (reward + gamma * V[next_state] * (not done))\n","            best_action_value = np.max(action_values)\n","            delta = max(delta, np.abs(best_action_value - V[state]))\n","            V[state] = best_action_value\n","            policy[state] = np.argmax(action_values)\n","        if delta < theta:\n","            break\n","    return policy, V"],"metadata":{"id":"ucTAkJELm5NI","executionInfo":{"status":"ok","timestamp":1748498100708,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def run_agent(env, policy, sleep_time=0.5):\n","    state, _ = env.reset()\n","    done = False\n","    while not done:\n","        env.render()\n","        time.sleep(sleep_time)\n","        action = policy[state]\n","        next_state, reward, done, _, _ = env.step(action)\n","        print(f\"State: {state} -> Action: {action} -> Next State: {next_state} -> Reward: {reward}\")\n","        state = next_state\n","    env.close()"],"metadata":{"id":"puMN6iKqm7Cc","executionInfo":{"status":"ok","timestamp":1748498108235,"user_tz":-330,"elapsed":21,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["policy_vi, values_vi = value_iteration(env)\n","\n","print(\"\\nOptimal Policy (Value Iteration):\")\n","print(policy_vi.reshape((4, 4)))\n","\n","print(\"\\nOptimal State Values (Value Iteration):\")\n","print(values_vi.reshape((4, 4)))\n","\n","print(\"\\nRunning agent using Value Iteration policy...\\n\")\n","run_agent(env, policy_vi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQCmLlV6m84G","executionInfo":{"status":"ok","timestamp":1748498129746,"user_tz":-330,"elapsed":14409,"user":{"displayName":"Kishore M","userId":"10139779576246080488"}},"outputId":"5843f499-995c-42db-fad4-14659c0138de"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Optimal Policy (Value Iteration):\n","[[0 3 0 3]\n"," [0 0 0 0]\n"," [3 1 0 0]\n"," [0 2 1 0]]\n","\n","Optimal State Values (Value Iteration):\n","[[0.06888624 0.06141117 0.07440763 0.05580502]\n"," [0.09185097 0.         0.11220727 0.        ]\n"," [0.14543392 0.24749561 0.29961676 0.        ]\n"," [0.         0.37993504 0.63901974 0.        ]]\n","\n","Running agent using Value Iteration policy...\n","\n","State: 0 -> Action: 0 -> Next State: 0 -> Reward: 0.0\n","State: 0 -> Action: 0 -> Next State: 0 -> Reward: 0.0\n","State: 0 -> Action: 0 -> Next State: 0 -> Reward: 0.0\n","State: 0 -> Action: 0 -> Next State: 4 -> Reward: 0.0\n","State: 4 -> Action: 0 -> Next State: 8 -> Reward: 0.0\n","State: 8 -> Action: 3 -> Next State: 4 -> Reward: 0.0\n","State: 4 -> Action: 0 -> Next State: 0 -> Reward: 0.0\n","State: 0 -> Action: 0 -> Next State: 4 -> Reward: 0.0\n","State: 4 -> Action: 0 -> Next State: 4 -> Reward: 0.0\n","State: 4 -> Action: 0 -> Next State: 8 -> Reward: 0.0\n","State: 8 -> Action: 3 -> Next State: 9 -> Reward: 0.0\n","State: 9 -> Action: 1 -> Next State: 13 -> Reward: 0.0\n","State: 13 -> Action: 2 -> Next State: 13 -> Reward: 0.0\n","State: 13 -> Action: 2 -> Next State: 14 -> Reward: 0.0\n","State: 14 -> Action: 1 -> Next State: 13 -> Reward: 0.0\n","State: 13 -> Action: 2 -> Next State: 14 -> Reward: 0.0\n","State: 14 -> Action: 1 -> Next State: 15 -> Reward: 1.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OjhGAjIJm-m_"},"execution_count":null,"outputs":[]}]}